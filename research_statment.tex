\documentclass[twoside,a4paper]{article}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1em}

\begin{document}
During my PhD I have worked mainly for the CMS experiment on that LHC at CERN.
On joining CMS I worked on designing an algorithm to identify jets for the level 
1 (L1) hardware trigger. By taking advantage of the increased granularity and 
flexibility of the upgraded system the new algorithm saw a significant increase in performance.
 
My main work has been on the all-hadronic αT search for new physics. As part of a 
team he worked on many parts of the analysis to rapidly interpret the 13TeV 
data taken in the 2015 run of the LHC to produce one of the 
first public SUSY results with this dataset. 

My initial contribution to the search built on the experience gained with the L1 trigger to help 
design the trigger strategy used for 2015 data taking. Following this, my 
main work on the analysis has been the responsibility for implementing and running the 
statistical framework for analysing the data collected by the search. I used this 
framework to make the final results and interpretations for supersymmetry models with the 2015
and 2016 datasets. These results were a vital tool in understanding 
the agreement of data with prediction and the interpretations have been shown publicly at 
several conferences. As part of this work, I updated the likelihood model 
used by the search to improve the accuracy of the correlation of the systematic 
uncertainties. As well as implementing the statistical analysis I helped design and code 
the main analysis framework. I was also responsible for efforts to significantly improve 
the sensitivity of the $\alpha_T$ search for a wide range of models while maintaining 
a robust analysis. I achieved this through the addition of templates to probe 
the distribution of the momentum imbalance for the events in the final selection. 
This additional information can be used to much improve the separation of signal models 
from backgrounds. 

Building on my experience with the statistical framework for $\alpha_T$, I worked with a collaborator 
in CMS to make a proposal for additional material to be released by CMS analyses
to allow their searches to be easily reinterpreted by those outside the collaboration. 
This can be done by defining a simplified likelihood based on the predictions and covariances
between analysis bins. A recommondation to release this information for all analyses
will be made in the SUSY and exotica groups. In addition, I have co-authored a public document 
describing generically how this may be used to reinterpret a search.

For the MasterCode collaboration I worked on a framework for 
deriving constraints from direct searches for new physics on GUT scale models of supersymmetry 
(SUSY). This required the rapid comprehension, implementation and validation of several 
searches from both the CMS and ATLAS experiments. Finally, he worked on 
showing that through combining several analysis targeting different final states the sensitivity of the 
limit to the non-flavoured sector of the SUSY spectra can be approximately 
removed. These ‘universal limits’ can be used to greatly reduce the 
time taken to sample a GUT model parameter space.
\end{document}
