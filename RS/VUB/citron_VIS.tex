\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{cancel}
\usepackage{xspace}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amscd}
\usepackage{amsfonts}
\usepackage{graphicx}%
\usepackage{fancyhdr}

% \usepackage[a4paper, total={7in, 8in}]{geometry}
\usepackage[bottom=0.4in,left=0.8in,right=0.8in]{geometry}
\usepackage{fancyhdr}

\theoremstyle{plain} \numberwithin{equation}{section}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}{Conjecture}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{finalremark}[theorem]{Final Remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{question}{Question} \topmargin-2cm

% \textwidth7in
%
% \setlength{\topmargin}{0in} \addtolength{\topmargin}{-\headheight}
% \addtolength{\topmargin}{-\headsep}
%
% \setlength{\oddsidemargin}{0in}
%\newcommand{\alphat}{\ensuremath{\alpha_{\text{T}}}\xspace}
\DeclareRobustCommand{\alphat}{$\alpha_{\text{T}}~$}
\DeclareRobustCommand{\met}{$\mbox{$E_\text{T}^{\rm miss}$}\xspace$}


% \oddsidemargin  0.0in \evensidemargin 0.0in

\pagestyle{fancy}\lhead{Matthew Citron}\rhead{May 2020}
\chead{{\large{\bf Vision of education and research}}} \lfoot{} \cfoot{\bf \thepage}

\newcounter{list}

\begin{document}
\section*{Vision of education and research}
%\section*{\fontsize{30}{30}\selectfont Statement of intent}
\noindent 
My research has focused on using data from the LHC to search for signatures of Beyond 
Standard Model (BSM) physics which may resolve 
fundamental problems in particle physics, such as the origin of dark matter. 
I feel that the best prospects for discovery comes from exploiting
the general purpose detectors in new and innovative ways and pursuing the construction
of new dedicated detectors. As described in detail below, 
I have had a leading role in the construction and
data analysis of the prototype milliQan detector at the LHC, leading a search for fractionally
charged particles that provided world-leading constrains. This also provided the 
opportunity to supervise and guide the work of many graduate and undergraduate students both
in building the detector and in data analysis. As a member of
the CMS collaboration I have pursued new approaches, undertaking a 
search which pioneered calorimetry timing to search for long-lived particles (LLPs) at CMS 
and using my position as EXO LL subgroup convenor to encourage new ideas.
% My search activities built on the experience gained during my PhD 
I also believe communication with theorist and experimentalistal colleages
across the field is critical to understanding the best prospects for 
new physics and possibilities for discovery. I have been actively involved
in phenomeological studies throughout my research and have
active involvement in the wider LLP community.

In the coming years the jumps in energies and luminosity that marked the previous running of the 
LHC will come to an end. While inclusive style analyses will continue to play a role in 
exploring ever larger phase space, new ideas and experiments will be critical to 
providing the best chance for discovery. In the following paragraphs I describe how the experience 
gained from my work on CMS and milliQan has prepared me well for the challenge 
of discovering BSM physics at the LHC.

\section*{Research activities}

\subsection*{The milliQan experiment}

In recent years there has been increasing interest in the possibility 
that astrophysical evidence for dark matter may indicate the existence 
of not just a single new particle but an entire "dark sector"
of particles and interactions with a rich and complex structure. The milliQan experiment 
was proposed in 2014 as a dedicated scintillator-based detector to search 
for millicharged particles ($\chi$), which can arise in dark sector models. 
The detector will consist of several layers of long scintillating bars pointing towards 
the interaction point at CMS, paired with high-gain, low-noise photomultiplier tubes (PMTs) 
capable of measuring a single scintillation photon. Such a design is necessary as the 
energy deposited by a millicharged particle 
is reduced by a factor of $Q/e^2$ compared to a particle of charge
$e$ with the same mass.

I joined the milliQan collaboration in Sept 2017 and immediately joined the
team installing a 1\% scale prototype designed to study the feasibility and
develop understanding of the experiment. The demonstrator is located in 
a challenging requirement that until 2020 could only be accessed when the LHC 
beam was not operational. During the first commissioning run, 
from September 2017 to January 2018, 
I helped write the framework needed to convert raw PMT waveforms into 
a format suitable for analysis and helped to constantly monitor
the data from the detector to ensure its smooth operation. While undertaking this 
monitoring I found a sudden spike in the trigger rate of the detector and determined
that this was due to the ramping down of the CMS magnetic field. This lead to the installation
of dedicated magnetic field sensors and additional shielding of the PMTs. As the magnetic field
was shown to negatively impact the performance of certain PMT species this also had
important ramifications for the choice of PMT for the full detector. In addition, I
found critical issues in the DAQ logic that caused signal like deposits to fail
trigger selection during early running.

In March 2018 I lead the upgrade of the demonstrator, which built on the experience 
gained during the first operational run, to expand the size of the active area
sensitive to signal deposits and add new components designed to shield the signal
sensitive area and measure backgrounds. I helped design the upgraded demonstrator,
helped constructed the new PMT and scintillator components as well as 
supervising both undergraduate and graduate students at UCSB undertaking this work.
The upgraded demonstrator took data for commissioning from March -- June 2018, during which 
time several issues were found and fixed in multiple interventions, before data suitable for physics
analysis was taken from June until proton-proton collisions stopped in late October 2018. 
The prototype detector collected a data set of 37.5 $fb^{-1}$, corresponding to 86\% of the total luminosity 
deliaved by the LHC in this period.

In January 2018 I was tasked with the analysis of data from the 
milliQan demonstrator. This invovled coordinating the activities of a group of approximately
15 postdocs, graduate students and undergraduates from various institutes in the US, Europe and Asia. 
The analysis objectives included the calibration of the data from the detector,
charaterising and measuring backgrounds, and simulating the generation and propagation of 
signals and backgrounds as well as the response of the detector. With these inputs I constructed
a search for millicharged particles using the prototype detector. Despite using sub-optimal PMTs 
and being only a small fraction of the size of the full milliqan detector,
this search achieved world-leading sensitivity to fractionally charged particles and has been formed
into a paper submitted to PRD~\cite{XX}.

The background measurements and mitigation strategies that I undertook for the search
with the milliQan demonstrator lead to important lessons for the design 
of the full milliQan detector. In particular, I was able to show 
that, contary to the assumption in the original experimental proposal, random overlap of dark rate counts
is a subdominant background source compared to the contribution from shower particles generated
by cosmic muons in the cavern. To mitigate this I proposed an alteration in the design of the detector from
three to four layers. The demonstrator was been altered to a four layer configuration and data collected from 
January -- May 2019 to directly measure background rates. This will be used to provide updated
projections in an upcoming paper (expected to be submitted by Autumn 2020).

\subsection*{Search for long-lived particles}

Over the last few years my main research interests have been in searching for 
beyond standard model theories which predict the existence of new particles
with non-negligible lifetimes. Such theories can have a wide range of motivations, 
including providing solutions to fundamental problems of cosmology, naturalness considerations,
providing a dark matter candidate and allowing non-zero neutrino masses. The discovery
of a new long-lived particle would be especially exciting as the non-trivial lifetime
provides a unique insight into the fundamental symmetries and heirachies of scale in the underlying model.
Searching for long-lived signatures produced in the proton-proton collisions at the LHC
with a general purpose detector such as CMS is particularly 
challenging due to the diffculties in triggering and reconstructing as well as
the prediction and rejection of non-standard backgrounds. 

During 2016 -- 2018 the LHC at CERN provided proton-proton collisions at a record energy of 13 TeV (Run 2).
In 2018 I started work on searching for LLPs in this data set with CMS, 
pioneering the use of calorimetry timing to search for LLPs decaying to jets. This analysis was the first carried 
out at CMS to target hadronic decays beyond the acceptance of the tracking detector and required a detailed
understanding of the timing and energy reconstruction performance of the electromagnetic calorimeter. 
The search also faced highly non-standard backgrounds, such as beam-halo muon deposits, cosmic muon deposits
and satellite bunch collisions, which cannot be reliably simulated. I therefore had to design 
dedicated variables to reject these backgrounds and predict their residual contributions using control regions
in data. By also requiring significant missing transverse momentum in the final state the search 
was able to achieve a low background with only a single displaced object in the final state. This allows
a wide sensitivity range in lifetime as well as providing a clear trigger strategy. The analysis achieved 
world leading limits for $\mathcal{O}$ TeV long-lived particles decaying to jets with $c\tau_{0} > 1$ m. 
The results were shown publicly at the Moriond Electroweak conference in 2018 and published in PLB in Octover 2019~\cite{XX}, 
the first search the first published search from CMS or ATLAS using the full data set collected in Run 2. 

While carrying out this search I began engaging with the wider LLP physics community. 
By attending and presenting at multiple workshops I was able to build connections with 
experimentalists and theorists working on LLPs and attain a wide view of different 
search strategies and well motivated theory models. In September 2019 I was appointed as
one of two CMS Exotica long-lived subgroup convenors, responsible for leading the 
LLP efforts within CMS as well as internal review of all CMS long-lived results. Since starting
my term, I have actively reviewed four new searches which have been made public to the wider community.
I have also made it a priority to increase the connections between different analysts within the
CMS long-lived group as well as between analysts and hardware, reconstruction 
and simulation experts within the CMS collaboration in order to find common solutions to 
common problems for long-lived analyses and to encourage the
adoption of new search strategies. To this end I have presented ideas for 
new triggers targeting signatures for Run 3 to the long-lived group 
and trigger experts on multiple occasions, as well as
presenting new ideas for using the hadronic calorimeter (HCAL) at the CMS HCAL workshop.
These have lead to dedicated studies on new triggers and analysis techniques being actively persued 
by a wide range of groups. In addition, with the co-convenor of the CMS EXO long-lived group, I 
organised the first CMS long-lived workshop in January 2020 with discussions 
of common issues for LLP searches including triggering, exploiting hardware upgrades, 
simulation, reconstruction and the use of machine learning for LLPs. 
The main aim of the workshop was to strengthen dialoge between long-lived analysts, 
reconstruction, simulation and object experts within CMS, and external theorists and
highlight new directions for long-lived particles in future runs of the LHC.  
The workshop was highly successful with over 100 participants and has been a starting 
point for multiple ongoing studies. My interest in long-lived physics expands beyond the scope of CMS
and milliQan and so in Febuary 2020 I joined the LHC LLP community organising committee 
and helped to organise the successful LHC LLP workshop in May 2020.

My main interest in searching for long-lived particles is exploiting new techniques and final states.
To this end, my research includes active involvement in the first search for displaced
hadronic decays in the CMS muon system, a search using machine learning to look for 
displaced decays of sterile neutrinos, investigating possible new triggers
for the upcoming run of the LHC using new handles from the CMS HCAL and the use
of timing information in searching for long-lived particles at the HL-LHC.

My interest in BSM physics extends beyond long-lived signatures during 
During my PhD (from 2013 -- 2017) I worked on the \alphat analysis searching
for BSM phyiscs in a final state containing jets and \met. 
The record energy reached for Run 2 of the LHC provided an excellent possibility of discovery
in the first months of operation. Taking advantage of this opportunity
required rapid and reliable analysis of this dataset. 
I held a pivotal role in ensuring the results from the \alphat analysis were among the 
first to be shown publicly with $2.3~{fb}^{-1}$ of data at CERN in November 2015
and with $12.9~{fb}^{-1}$ of data at ICHEP16, for which I gave the successful
approval talk. My key involvement in the analysis allowed me to gain important experience 
in quickly and robustly understanding and then analysing data to search for BSM physics. 

\subsection*{Phenomenology}

As part of the MasterCode collaboration from 2012 -- 2018 I developed a framework for 
deriving constraints from direct searches for BSM physics on GUT scale models of SUSY.
This required the comprehension, implementation and validation of several 
searches from both the CMS and ATLAS experiments. Using this framework, I worked to show that through combining several inclusive analyses targeting 
different final states the sensitivity of the limit to the non-coloured sector of the SUSY spectra can be approximately removed. 
These `universal limits' can be used to greatly reduce the time taken to sample a GUT model parameter space. 
Through this work, I also gained experience with event generation (PYTHIA) as well as fast detector simulation (DELPHES)~\cite{XX}.

In addition to my work for the mastercode collaboration I have worked on 
studies of the discovery potential for SUSY at future colliders and how 
metastable supersymmetric taus (staus), predicted in certain SUSY models to provide the observed
dark matter relic density, may be discovered by experiments at the LHC~\cite{XX}. 
This work on metastable staus was one of the first considerations of long-lived decays to taus, which
is rapidly gaining in interest within the community.

My phenomenology experience has been very useful in understanding
the kinds of models that are well motivated theoretically and evade current experimental limits and may be targeted in the 
future. I have also gained an appreciation
of the information which is needed to reliably reinterpret an analysis and so which should be released in CMS publications.

Independently from my group, I worked with a collaborator in CMS to make a proposal 
for additional material to be released by CMS analyses
to allow their searches to be easily reinterpreted by those outside the collaboration. 
This work built on my experience with the statistical framework for $\alpha_T$ as well as being 
informed by my work with the MasterCode collaboration. The predictions and covariances between analysis bins may be used
to define a simplified likelihood to allow reinterpretation for any search. 
A recommendation to release this information for all analyses
will be made in the SUSY and Exotica groups. In addition, I co-authored a public document,
describing generically how this may be used to reinterpret a search. This work formed the
basis of a paper which looked more generally at how likelihoods may be reinterpreted~\cite{XX}

 \section*{Research Plans}

 My extensive experience in

 \begin{itemize}
 \item rapid data comprehension and analysis
 \item designing new search techniques and optimising sensitivity for BSM physics signatures
 \item building, designing and analysing data from the milliQan prototype
 \item phenomenology
 \end{itemize}

 will allow me to take a leading and pivotal role in searches for BSM physics and new experiments.
 I would like to continue searching for signatures of such BSM physics using CMS data from collisions at the LHC
 and pursue the construction of a full scale milliQan detector at the LHC or elsewhere. 
 As inclusive searches have failed  to uncover any evidence for BSM physics, 
 I believe the best opportunity for discovery will 
 come from novel techniques and dedicated experiements to exploit the data produced
 by continued LHC operation at 13 TeV. 

 Over the last three years as a Post doctoral researcher student on CMS and milliQan
 I have seized the opportunity to gain experience with new search techniques and a dedicated
 low background detector. I have taken on leading roles and
 have had extensive involvement with the wider long-lived particle community. 
 Finally, in my work with milliQan and more recent search efforts within CMS I have greatly enjoyed
 the opportunity to supervise the work of students.

 I am eager to build on my experience in analysis and hardware to play 
 a pivotal role in searches for BSM physics as the LHC
 moves into a new and exciting phase. The position at VUB provides the perfect opportunity to
 strengthen my activities within the milliQan collaboration and make VUB the European centre
 for construction of the full milliQan detector.
 
%\clearpage\end{CJK*}                              % if you are typesetting your resume in Chinese using CJK; the \clearpage is required for fancyhdr to work correctly with CJK, though it kills the page numbering by making \lastpage undefined
\end{document}


%% end of file `template.tex'.
